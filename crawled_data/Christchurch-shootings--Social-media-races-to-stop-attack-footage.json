{"title": "Christchurch shootings: Social media races to stop attack footage", "content": "A gunman opened fire in a mosque in Christchurch, New Zealand, killing 50 people and injuring 50 more. As he did so, he filmed the entire crime and live-streamed it directly to Facebook.\nWhat ensued was an exhausting race for social media pages to take the footage down, as it was replicated seemingly endlessly and shared widely in the wake of the attack.\nAnd through social media, it found its way onto the front pages of some of the world's biggest news websites in the form of still images, gifs, and even the full video.\nThis series of events has, once again, shone a spotlight on how sites like Twitter, Facebook, YouTube and Reddit try - and fail - to address far-right extremism on their platforms.\nAs the video continued to spread, other members of the public put up their own posts pleading with people to stop sharing it.\nOne pointed out: \"That is what the terrorist wanted.\"\nThe video, which shows a first-person view of the killings, has been widely circulated.\nWhile huge numbers of people have been duplicating and sharing the footage online, many others responded with disgust - urging others not only not to share the footage, but not even to watch it.\nSpreading the video, many said, was what the attacker had wanted people to do.\nA lot of people were particularly angry at media outlets for publishing the footage. \nChannel 4 News anchor Krishnan Guru-Murthy, for example, specifically named two British newspaper websites and accused them of hitting \"a new low in clickbait\".\nBuzzfeed reporter Mark Di Stefano also wrote that MailOnline had allowed readers to download the attacker's 74-page \"manifesto\" from their news report. The website later removed the document, and released a statement saying it was \"an error\". \nDaily Mirror editor Lloyd Embley also tweeted that they had removed the footage, and that publishing it was \"not in line with our policy relating to terrorist propaganda videos\".\nAll of the social media firms have sent heartfelt sympathy to the victims of the mass shootings, reiterating that they act quickly to remove inappropriate content. \nFacebook said: \"New Zealand Police alerted us to a video on Facebook shortly after the live-stream commenced and we removed both the shooter's Facebook account and the video.\n\"We're also removing any praise or support for the crime and the shooter or shooters as soon as we're aware. We will continue working directly with New Zealand Police as their response and investigation continues.\"\nAnd in a tweet, YouTube said \"our hearts are broken\", adding it was \"working vigilantly\" to remove any violent footage.\nIn terms of what they have done historically to combat the threat of far-right extremists, the social media companies' approach has been more chequered. \nTwitter acted to remove alt-right accounts in December 2017. Previously it has removed and then reinstated the account of Richard Spencer, an American white nationalist who popularised the term \"alternative right\".\nFacebook, which suspended Mr Spencer's account in April 2018, admitted at the time that it was difficult to distinguish between hate speech and legitimate political speech.\nThis month, YouTube was accused of being either incompetent or irresponsible for its handling of a video promoting the banned Neo-Nazi group, National Action.\nBritish MP Yvette Cooper said the video-streaming platform had repeatedly promised to block it, only for it to reappear on the service.\nDr Ciaran Gillespie, a political scientist from Surrey University, thinks the problem goes far deeper than a video, shocking as that content has been.\n\"It is not just a question about broadcasting a massacre live. The social media platforms raced to close that down and there is not much they can do about it being shared because of the nature of the platform, but the bigger question is the stuff that goes before it,\" he said.\nAs a political researcher, he uses YouTube \"a lot\" and says that he is often recommended far-right content.\n\"There is oceans of this content on YouTube and there is no way of estimating how much. YouTube has dealt well with the threat posed by Islamic radicalisation, because this is seen as clearly not legitimate, but the same pressure does not exist to remove far-right content, even though it poses a similar threat.\n\"There will be more calls for YouTube to stop promoting racist and far-right channels and content.\"\nHis views are echoed by Dr Bharath Ganesh, a researcher at the Oxford Internet Institute.\n\"Taking down the video is obviously the right thing to do, but social media sites have allowed far-right organisations a place for discussion and there has been no consistent or integrated approach to dealing with it. \n\"There has been a tendency to err on the side of freedom of speech, even when it is obvious that some people are spreading toxic and violent ideologies.\"\nNow social media companies need to \"take the threat posed by these ideologies much more seriously\", he added.\n\"It may mean creating a special category for right-wing extremism, recognising that it has global reach and global networks.\"\nNeither under-estimate the magnitude of the task, especially as many of the exponents of far-right views are adept at, what Dr Gillespie calls, \"legitimate controversy\".\n\"People will discuss the threat posed by Islam and acknowledge it is contentious but point out that it is legitimate to discuss,\" he said.\nThese grey areas are going to be extremely difficult for the social media firms to tackle, they say, but after the tragedy unfolding in New Zealand, many believe they must try harder.  ", "date": "16 March 2019", "href": "https://www.bbc.com/news/technology-47583393", "tags": "content youtube media shootings video social facebook stop footage christchurch attack far-right races"}