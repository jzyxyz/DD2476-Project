{"title": "Who is to blame for 'self-driving car' deaths?", "content": "The confusion between fully autonomous self-driving cars and those that simply offer driver assistance technologies is leading to deaths on the road. Who is to blame and what should be done about it?\nSelf-driving cars already exist and there will be more of them in future, but the chances are that you won't be driven by one any time soon. \nYou may, however, already be using a car that can steer, brake or park by itself. \nThe fear is that the hype around driverless cars has led some drivers to test the limits of existing technology in ways that are downright reckless.\nA Tesla driver in the UK, for example, was recently prosecuted for climbing into the passenger seat of his car while it was moving at around 40mph (64km/h) in motorway traffic.\nHe was using Tesla's Autopilot, a system that does allow the car to accelerate, brake and steer by itself on major roads, but is not designed to completely replace a driver.\nOther manufacturers such as Volvo, Mercedes-Benz and Cadillac have similar mechanisms. \nBut none of them is designed to be fully autonomous. \nUsing standard criteria established by the US engineering organisation SAE International, cars can be placed into six broad categories depending on the level of automation they contain.\nThey range from Level Zero, where the vehicle is not automated at all, to Level 5, which means it can drive itself on all roads and in all conditions, making the human behind the wheel - and the steering wheel itself - redundant. \nCurrent \"driver assistance\" systems are Level 2 in the jargon, and the driver is meant to keep his or her hands firmly on the wheel.\nBut getting that message across has clearly been a challenge. \nTesla's Autopilot in particular has been implicated in a number of high profile crashes, two of them fatal. \nThe company denies claims that the Autopilot name itself encourages drivers to hand over control, and has rejected demands from the German government to stop using the term.\nIt says feedback from its customers has shown that \"they have a very clear understanding of what Autopilot is, how to properly use it and what features it consists of\". \nNevertheless, since 2016 Tesla's systems have included more prominent warnings to drivers to keep their hands on the wheel, and have been able to lock them out of Autopilot if they fail to do so.\nThat same year, Mercedes faced criticism over advertising that suggested its E-Class was a \"self-driving car\".  \nIt later withdrew the adverts, in response, it said, to claims that customers could find them confusing.\nAlthough ride-sharing firms like Lyft and Uber have been working hard on developing fully autonomous technology - as have many mainstream manufacturers - Level 5 cars are still some way off. \nWaymo appears to be closer than most.\nLater this year Google's sister company is planning to introduce a driverless taxi service in Phoenix, Arizona. Unlike several other autonomous taxi services being trialled around the world, this one will not need a safety driver in the car.\nBut the service will only operate in a relatively small \"geo-fenced\" area of Phoenix that the company has intensively mapped. It is still, in effect, a test-bed. \nThere is a big step between this kind of limited service and something that can safely negotiate a densely populated mega-city in all weathers.\n\"Testing and development is different from bringing onto the market,\" explains Prof Walter Brenner of the University of St Gallen in Switzerland and co-author of Autonomous driving - how the driverless revolution will change the world.\n\"They are completely different worlds. The tests are useful because they show both the strengths and the limits of this technology, but they are just tests.\"\nEarlier this year, a woman was killed in Arizona by an Uber test car being driven in autonomous mode. It failed to stop when she moved into its path.\nClearly, despite all the research being carried out and the money being spent, there is still a lot of work to do before full autonomy becomes a safe, everyday reality.\nSafety experts believe car companies need to take more responsibility for ensuring consumers don't make mistakes.\n\"Calling this kind of technology Autopilot\u2026 that's very misleading for consumers,\" says Matthew Avery of Thatcham Research - a group that tests vehicles on behalf of the UK insurance industry. \n\"They might think 'I just need to push this button and I can let the car drive'.\"\nMore Technology of Business\nHe also thinks manufacturers should take further steps to ensure the technology isn't abused, such as having cameras monitoring the driver. \nBut he remains convinced that automation itself has vital safety benefits.\nThere is already evidence that automatic emergency braking and pedestrian detection systems are reducing the number of accidents. But more sophisticated systems can take that process a step further.\n\"What the best systems are doing is integrating lane control, stopping people veering out of their lane, with braking control and distance control. \n\"That can really help keep people out of trouble,\" he says.\nWalter Brenner believes there's a need for drivers - and people selling cars - to be better educated about what semi-automated systems can do. \nThere is a risk, he concedes, that even with that knowledge some people might deliberately choose to let the technology do more than it should - to experiment with it, or even to show off.\nIn those cases, he thinks, punishments should be harsh.\n\"There's a big difference between trying out a new feature on an iPhone and playing with technology in a car when you're travelling at 100km/h (62mph) on a public road,\" he says.\n\"Those people have to be punished because they're risking other people's lives.\"", "date": "22 May 2018", "href": "https://www.bbc.com/news/business-44159581", "tags": "cars autonomous level using deaths driver autopilot systems blame car technology"}