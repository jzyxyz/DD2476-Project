{"title": "Facial Recognition Software Moves From Overseas Wars to Local Police", "content": "SAN DIEGO \u2014 Facial recognition software, which American military and intelligence agencies used for years in Iraq and Afghanistan to identify potential terrorists, is being eagerly adopted by dozens of police departments around the country to pursue drug dealers, prostitutes and other conventional criminal suspects. But because it is being used with few guidelines and with little oversight or public disclosure, it is raising questions of privacy and concerns about potential misuse.\nLaw enforcement officers say the technology is much faster than fingerprinting at identifying suspects, although it is unclear how much it is helping the police make arrests.\nWhen Aaron Harvey was stopped by the police here in 2013 while driving near his grandmother\u2019s house, an officer not only searched his car, he said, but also took his photograph and ran it through the software to try to confirm his identity and determine whether he had a criminal record.\nEric Hanson, a retired firefighter, had a similar experience last summer. Stopped by the police after a dispute with a man he said was a prowler, he was ordered to sit on a curb, he said, while officers took his photo with an iPad and ran it through the same facial recognition software. The officers also used a cotton swab to collect a DNA sample from the inside of his cheek.\nNeither man was arrested. Neither had consented to being photographed. Both said officers had told them that they were using facial recognition technology.\n\u201cI was thinking, \u2018Why are you taking pictures of me, doing this to me?\u2019 \u201d said Mr. Hanson, 58, who has no criminal record. \u201cI felt like my identity was being stolen. I\u2019m a straight-up, no lie, cheat or steal guy, and I get treated like a criminal.\u201d\nLt. Scott Wahl, a spokesman for the 1,900-member San Diego Police Department, said the department does not require police officers to file a report when they use the facial recognition technology but do not make an arrest. The department has no record of the stops involving Mr. Hanson and Mr. Harvey, and Lieutenant Wahl said that he did not know about the incidents but that they could have happened.\n\u201cIt is a test product for the region that we\u2019ve allowed officers to use,\u201d he said of facial recognition software and the hand-held devices the police use to take pictures. \u201cWe don\u2019t even know how many are out there\u201d in the region.\nHe said that until June 19, his department did not have a written policy regulating facial recognition software and only recently began training officers on its lawful use. Before then, he said, there were interim regional guidelines and training available.\nCounty documents show that since 2011, 26 San Diego law enforcement agencies used the software to try to identify people on more than 20,600 occasions \u2014 although officers found a match to criminal records only about 25 percent of the time.\nLieutenant Wahl said the department was not aware of any complaints about the software or about the policy of collecting DNA samples that Mr. Hanson and others have described.\nThe department uses the technology judiciously, Lieutenant Wahl said. \u201cWe don\u2019t just drive around taking people\u2019s picture and start swabbing them,\u201d he said.\nOthers say misuse is common.\n\u201cI get a call about facial recognition maybe twice a month,\u201d said Victor Manuel Torres, a San Diego civil rights lawyer. \u201cThe complaint is always that they did it and didn\u2019t get permission. \u2018The police put me in cuffs and I\u2019m on the curb, and they pull out an iPad and are taking pictures.\u2019 \u201d\nThe Police Department, which the Justice Department recently determined to have a history of serious misconduct, has also been found to disproportionately stop and search African-Americans. But there is no similar racial breakdown for facial recognition checks, in part because the department does not keep the data.\n\u201cIt is not as if there is the identification of a specific crime problem; they are simply collecting a lot of information that could impact a lot of completely innocent people,\u201d said Michael German, a fellow at the Brennan Center for Justice and a former F.B.I. agent. \u201cThere is very little oversight on the local level, and little concern from the federal agencies providing the grants.\u201d\nFacial recognition technology was first developed in the 1960s, but only recently became accurate enough for widespread use. It is among an array of technologies, including StingRay tracking devices and surveillance aircraft with specialized cameras, that were used in overseas wars but have found their way into local law enforcement.\nThe software can identify 16,000 points on a person\u2019s face \u2014 to determine the distance between the eyes or the shape of the lips, for instance \u2014 and compare them with thousands of similar points in police booking or other photos at a rate of more than one million faces a second.\nThe technology is so new that experts say they are unaware of major legal challenges. In some cities, though, a backlash is stirring.\nIn Northern California, the Oakland City Council, under pressure from residents and civil liberties advocates, scaled back plans this year for a federally financed center that would have linked surveillance equipment around the city, including closed-circuit cameras, gunshot microphones and license plate readers. It also formed a committee to limit the use of this equipment and to develop privacy standards, like how long data may be kept and who will have access to it.\nThe authorities in Boston tested facial recognition technology but decided in 2013 not to adopt it, saying it crossed an ethical line. The software had been linked to surveillance cameras to secretly scan the faces of thousands of people at outdoor concerts in the city center. The images had then been fed into software capable of analyzing them.\n\u201cI don\u2019t want people to think we\u2019re always spying on them,\u201d said William B. Evans, Boston\u2019s police commissioner.\nYet the F.B.I. is pushing ahead with its $1 billion Next Generation Identification program, in which the agency will gather data like fingerprints, iris scans and photographs, as well as information collected through facial recognition software. That software is capable of analyzing driver\u2019s license photos and images from the tens of thousands of surveillance cameras around the country. The F.B.I. system will eventually be made accessible to more than 18,000 local, state, federal and international law enforcement agencies.\nBut people who are not criminal suspects are included in the database, and the error rate for the software is as high as 20 percent \u2014 meaning the authorities could misidentify millions of people.\nAmong the cities that use facial recognition technology are New York and Chicago, which has linked it to 25,000 surveillance cameras in an effort to fight street crime.\nIn many ways, though, San Diego County is at the forefront.\nHere, beat cops, detectives and even school police officers have been using hand-held devices to create a vast database of tens of thousands of photos of people like Mr. Harvey and Mr. Hanson \u2014 some suspected of committing crimes, others not \u2014 usually without the person\u2019s consent.\nNot everyone is opposed to such programs. Last year, Tom Northcutt, a San Diego property manager, took an iPhone photo of a man moments before the man struck him in the arm with a two-by-four and fled. Mr. Northcutt, who did not know the aggressor, immediately sent the image to the police by email.\nLess than 10 minutes later, a detective matched the man to a booking photograph of a suspect, who was arrested and later convicted of assault.\n\u201cIt felt good knowing that they could do that,\u201d Mr. Northcutt said.\nMr. Harvey, 27, remains upset about what happened to him. He said that when he refused to consent to having his picture taken, the officer boasted that he could do so anyway.\n\u201cHe said, \u2018We\u2019re going to do this either legally or illegally,\u2019 and pulled me out of the car,\u201d Mr. Harvey said.\nMr. Harvey, who is African-American, said the San Diego Police had stopped him as a suspected gang member more than 50 times because his neighborhood, Lincoln Park, is among the city\u2019s most violent.\nHe said he had been told he was in a gang database, even though he has never been a gang member. He recently spent nearly a year in jail on gang conspiracy charges that were dismissed in March. \u201cI don\u2019t know how good a gang member I could have been, not having a criminal record,\u201d he said.\nMr. Hanson, who is white and lives in the city\u2019s upscale Ocean Beach neighborhood, said his treatment by officers had been as intrusive as it was frightening.\n\u201cI\u2019m not a lawyer,\u201d he said, \u201cbut they didn\u2019t appear to be following the law.\u201d", "date": "Aug. 12, 2015", "href": "https://www.nytimes.com/2015/08/13/us/facial-recognition-software-moves-from-overseas-wars-to-local-police.html", "tags": "officers overseas software \u201c facial wars local recognition department police moves"}