{"title": "Websites to be fined over 'online harms' under new proposals", "content": "Internet sites could be fined or blocked if they fail to tackle \"online harms\" such as terrorist propaganda and child abuse, under government plans.\nThe Department for Digital, Culture, Media and Sport (DCMS) has proposed an independent watchdog that will write a \"code of practice\" for tech companies.\nSenior managers could be held liable for breaches, with a possible levy on the industry to fund the regulator. \nBut critics say the plans threaten freedom of speech.\nThe Online Harms White Paper is a joint proposal from the DCMS and the Home Office. A public consultation on the plans will run for 12 weeks.\nThe paper suggests:\nOutlining the proposals, Culture Secretary Jeremy Wright said: \"The era of self-regulation for online companies is over.\n\"Voluntary actions from industry to tackle online harms have not been applied consistently or gone far enough.\"\nDiscussing potential penalties on BBC Breakfast, he said: \"If you look at the fines available to the Information Commissioner around the GDPR rules, that could be up to 4% of company's turnover... we think we should be looking at something comparable here.\"\nThe plans cover a range of issues that are clearly defined in law such as spreading terrorist content, child sex abuse, so-called revenge pornography, hate crimes, harassment and the sale of illegal goods.\nBut it also covers harmful behaviour that has a less clear legal definition such as cyber-bullying, trolling and the spread of fake news and disinformation.\nIt says social networks must tackle material that advocates self-harm and suicide, which became a prominent issue after 14-year-old Molly Russell took her own life in 2017. \nAfter she died her family found distressing material about depression and suicide on her Instagram account. Molly's father Ian Russell holds the social media giant partly responsible for her death.\nMr Russell told the BBC that the white paper was \"a very important step\" towards making the internet a safer place.\n\"I think after what we've been through and sadly what so many families go through, the urgency is huge,\" he said.\nHowever he added that the paper could have contained more specific guidance for parents.\n\"For example, there's not very much about age limits and ratings - it seems to me lots of companies self-rate their apps and their content and that makes it very difficult for a parent to know how much they can trust those platforms,\" he said. \nHome Secretary Sajid Javid said tech giants and social media companies had a moral duty \"to protect the young people they profit from\".\n\"Despite our repeated calls to action, harmful and illegal content - including child abuse and terrorism - is still too readily available online.\nThe plans call for an independent regulator to hold internet companies to account. \nIt would be funded by the tech industry. The government has not decided whether a new body will be established, or an existing one handed new powers.\nThe regulator will define a \"code of best practice\" that social networks and internet companies must adhere to.\nAs well as Facebook, Twitter and Google, the rules would apply to messaging services such as Snapchat and cloud storage services.\nThe regulator will have the power to fine companies and publish notices naming and shaming those that break the rules.\nThe government says it is also considering fines for individual company executives and making search engines remove links to offending websites.\nIt is also consulting over blocking harmful websites.\nOn the face of it, this is a tough new regime - and ministers have acted upon the demands of charities like the NSPCC which want what they regard as the \"Wild West Web\" to be tamed. \nBut a closer look reveals all sorts of issues yet to be settled. \nWill a whole new organisation be given the huge job of regulating the internet? Or will the job be handed to the media regulator Ofcom? \nWhat sort of sanctions will be available to the regulator? And will they apply equally to giant social networks and to small organisations such as parents' message boards?\nMost tricky of all is how the regulator is going to rule on material that is not illegal but may still be considered harmful.\nTake this example. Misinformation is listed as a potential harm, and Health Secretary Matt Hancock has talked about the damaging effects anti-vaccination campaigners have had. \nSo will the regulator tell companies that their duty of care means they must remove such material? \nThe government now plans to consult on its proposals. It may yet find that its twin aims of making the UK both the safest place in the world online and the best to start a digital business are mutually incompatible.\nThe white paper offers some suggestions that could be included in the code of best practice.\nIt suggests the spread of fake news could be tackled by forcing social networks to employ fact-checkers and promote legitimate news sources.\nBut the regulator will be allowed to define the code by itself.\nThe white paper also says social media companies should produce annual reports revealing how much harmful content has been found on their platforms.\nThe children's charity NSPCC has been urging new regulation since 2017 and has repeatedly called for a legal duty of care to be placed on social networks.\nA spokeswoman said: \"Time's up for the social networks. They've failed to police themselves and our children have paid the price.\"\nRebecca Stimson, Facebook's head of UK policy, said in a statement: \"New regulations are needed so that we have a standardised approach across platforms and private companies aren't making so many important decisions alone. \n\"New rules for the internet should protect society from harm while also supporting innovation, the digital economy and freedom of speech.\"\nTwitter's head of UK public policy Katy Minshall said in a statement: \"We look forward to engaging in the next steps of the process, and working to strike an appropriate balance between keeping users safe and preserving the open, free nature of the internet.\"\nTechUK, an umbrella group representing the UK's technology industry, said the government must be \"clear about how trade-offs are balanced between harm prevention and fundamental rights\".\nJim Killock, executive director of Open Rights Group, said the government's proposals would \"create state regulation of the speech of millions of British citizens\".\nMatthew Lesh, head of research at free market think tank the Adam Smith Institute, went further.\nHe said: \"The government should be ashamed of themselves for leading the western world in internet censorship. \n\"The proposals are a historic attack on freedom of speech and the free press.\n\"At a time when Britain is criticising violations of freedom of expression in states like Iran, China and Russia, we should not be undermining our freedom at home.\"\nAnd freedom of speech campaigners Article 19 warned that the government \"must not create an environment that encourages the censorship of legitimate expression\".\nA spokesman said it opposed any duty of care being imposed on internet platforms.\nThey said that would \"inevitably require them to proactively monitor their networks and take a restrictive approach to content removal\". \n\"Such actions could violate individuals' rights to freedom of expression and privacy,\" they added.\nThe BBC has a digital guide to life online for parents and young people: BBC Own It", "date": "8 April 2019", "href": "https://www.bbc.com/news/technology-47826946", "tags": "companies proposals regulator social online networks fined harms could new internet freedom websites government"}