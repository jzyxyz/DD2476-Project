{"title": "'Bots used to bias online political chats'", "content": "If you've been chatting about politics on social media recently, there's a good chance you've been part of a conversation that was manipulated by bots, researchers say.\nThe Oxford Internet Institute (OII) has studied such discussions related to nine places - US, Russia, Ukraine, Germany, Canada, China, Taiwan, Brazil and Poland - on platforms including Twitter and Facebook. \nIt claims that in all the elections, political crises and national security-related discussions it looked at, there was not one instance where social media opinion had not been manipulated.\nBots - programs that perform simple, repetitive tasks - are integral to what the OII calls \"computational propaganda\" - instances of people deliberately distributing misleading information on social media by various means.  \nBots can communicate with people - retweeting fake news, for example - but they can also exploit social network algorithms to get a topic to trend.\nThey can be fully or only partly automated. A single individual can use them to create the illusion of large-scale consensus. They can also be used to stifle critics by mobbing individuals or swamping hashtags. \nThe methods the OII used for identifying bots in each country study varied. \nThe institute has, however, been criticised in the past for identifying social media accounts as being \"bots\" whose owners insisted they were nothing of the kind.\nBots are built by authoritarian governments, by corporate consultants who hire out their expertise, or by individuals who have the know-how, says the OII.\n\"Because the Twitter API [application programming interface - the means by which one bit of software can talk to another] is open, anyone can launch a bot on Twitter,\" explained director of research for the project, Samuel Woolley.\nSee also:\nOne in eight UK election Twitter links is 'junk'\nMassive networks of fake accounts found on Twitter\nClinton bots 'hit back in second debate'\nWhile bot and other propagandistic behaviour was specific to the political context of each country, the study also identified several trends.\nIn every country, it said, civil society groups struggled to protect themselves against misinformation campaigns.\nAnd in authoritarian countries, it added, social media was one of the key ways the authorities had tried to retain control during political crises.\nComputational propaganda has been particularly prevalent in Ukraine, the research suggests.\nThere had been \"significant Russian activity... to manipulate public opinion\" the report said, adding that Ukraine had become \"the frontline of numerous disinformation campaigns\" since 2014. \nThe typical way this worked, it explained, was that a message would be placed in an online news outlet or blog's article. \nThis was possible, it said, \"because a large number of Ukrainian online media... publish stories for money\".\nThese would then be spread on social media via automated accounts and potentially picked up in turn by \"opinion leaders\", with large followings of their own.\nWith enough attention, the message would ultimately be picked up by mainstream media, including TV channels.\nThe study provides an example related to the shooting down of Malaysian Airlines flight MH17 in 2014 to illustrate how such campaigns work.\nA conspiracy theory claiming that the plane was shot down by a Ukranian fighter jet originated with a tweet from a non-existent Spanish air traffic controller, called Carlos (@spainbuca).\nThe post was then retweeted by others and was picked up by Russia's RT television network as well as other Russian news outlets. \nUkraine's information ministry later revealed the account had been used to retweet pro-Russian messages earlier in the year.\nIn Russia itself, the OII suggested that about 45% of politics-focused Twitter accounts were highly automated, \"essentially reproducing government propaganda\".\nIt remains difficult to quantify the impact such bots have had. \nBut the OII's researchers believe that \"computational propaganda is now one of the most powerful tools against democracy\". \nThey have called on social media firms to do more to tackle the issue.\nLead researcher Prof Philip Howard proposed several steps that could be taken by the tech firms, including:\nProf Howard cautioned, however, that governments must be careful not to over-regulate the technology for fear of suppressing political conversation on social media altogether.\nIn response, Twitter reissued a statement saying that third-party research into bots on its platform was \"often inaccurate and methodologically flawed\".\nIt added that it strictly prohibited bots and would \"make improvements on a rolling basis to ensure our tech is effective in the face of new challenges\".\nA spokeswoman from Facebook was unable to provide comment.", "date": "21 June 2017", "href": "https://www.bbc.co.uk/news/technology-40344208", "tags": "bias propaganda media used twitter political social bots online one ukraine also chats oii"}