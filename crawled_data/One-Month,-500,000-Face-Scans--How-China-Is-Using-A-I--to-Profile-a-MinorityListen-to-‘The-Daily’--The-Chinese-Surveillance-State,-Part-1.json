{"title": "One Month, 500,000 Face Scans: How China Is Using A.I. to Profile a MinorityListen to \u2018The Daily\u2019: The Chinese Surveillance State, Part 1", "content": "The Chinese government has drawn wide international condemnation for its harsh crackdown on ethnic Muslims in its western region, including holding as many as a million of them in detention camps. \nNow, documents and interviews show that the authorities are also using a vast, secret system of advanced facial recognition technology to track and control the Uighurs, a largely Muslim minority. It is the first known example of a government intentionally using artificial intelligence for racial profiling, experts said.\nThe facial recognition technology, which is integrated into China\u2019s rapidly expanding networks of surveillance cameras, looks exclusively for Uighurs based on their appearance and keeps records of their comings and goings for search and review. The practice makes China a pioneer in applying next-generation technology to watch its people, potentially ushering in a new era of automated racism.\nThe technology and its use to keep tabs on China\u2019s 11 million Uighurs were described by five people with direct knowledge of the systems, who requested anonymity because they feared retribution. The New York Times also reviewed databases used by the police, government procurement documents and advertising materials distributed by the A.I. companies that make the systems. \nChinese authorities already maintain a vast surveillance net, including tracking people\u2019s DNA, in the western region of Xinjiang, which many Uighurs call home. But the scope of the new systems, previously unreported, extends that monitoring into many other corners of the country. \nThe police are now using facial recognition technology to target Uighurs in wealthy eastern cities like Hangzhou and Wenzhou and across the coastal province of Fujian, said two of the people. Law enforcement in the central Chinese city of Sanmenxia, along the Yellow River, ran a system that over the course of a month this year screened whether residents were Uighurs 500,000 times. \nPolice documents show demand for such capabilities is spreading. Almost two dozen police departments in 16 different provinces and regions across China sought such technology beginning in 2018, according to procurement documents. Law enforcement from the central province of Shaanxi, for example, aimed to acquire a smart camera system last year that \u201cshould support facial recognition to identify Uighur/non-Uighur attributes.\u201d\nSome police departments and technology companies described the practice as \u201cminority identification,\u201d though three of the people said that phrase was a euphemism for a tool that sought to identify Uighurs exclusively. Uighurs often look distinct from China\u2019s majority Han population, more closely resembling people from Central Asia. Such differences make it easier for software to single them out.\nFor decades, democracies have had a near monopoly on cutting-edge technology. Today, a new generation of start-ups catering to Beijing\u2019s authoritarian needs are beginning to set the tone for emerging technologies like artificial intelligence. Similar tools could automate biases based on skin color and ethnicity elsewhere.\n\u201cTake the most risky application of this technology, and chances are good someone is going to try it,\u201d said Clare Garvie, an associate at the Center on Privacy and Technology at Georgetown Law. \u201cIf you make a technology that can classify people by an ethnicity, someone will use it to repress that ethnicity.\u201d\nFrom a technology standpoint, using algorithms to label people based on race or ethnicity has become relatively easy. Companies like I.B.M. advertise software that can sort people into broad groups. \nBut China has broken new ground by identifying one ethnic group for law enforcement purposes. One Chinese start-up, CloudWalk, outlined a sample experience in marketing its own surveillance systems. The technology, it said, could recognize \u201csensitive groups of people.\u201d \n\u201cIf originally one Uighur lives in a neighborhood, and within 20 days six Uighurs appear,\u201d it said on its website, \u201cit immediately sends alarms\u201d to law enforcement.\nIn practice, the systems are imperfect, two of the people said. Often, their accuracy depends on environmental factors like lighting and the positioning of cameras.\nIn the United States and Europe, the debate in the artificial intelligence community has focused on the unconscious biases of those designing the technology. Recent tests showed facial recognition systems made by companies like I.B.M. and Amazon were less accurate at identifying the features of darker-skinned people.\nChina\u2019s efforts raise starker issues. While facial recognition technology uses aspects like skin tone and face shapes to sort images in photos or videos, it must be told by humans to categorize people based on social definitions of race or ethnicity. Chinese police, with the help of the start-ups, have done that.\n\u201cIt\u2019s something that seems shocking coming from the U.S., where there is most likely racism built into our algorithmic decision making, but not in an overt way like this,\u201d said Jennifer Lynch, surveillance litigation director at the Electronic Frontier Foundation. \u201cThere\u2019s not a system designed to identify someone as African-American, for example.\u201d\nThe Chinese A.I. companies behind the software include Yitu, Megvii, SenseTime, and CloudWalk, which are each valued at more than $1 billion. Another company, Hikvision, that sells cameras and software to process the images, offered a minority recognition function, but began phasing it out in 2018, according to one of the people.\nThe companies\u2019 valuations soared in 2018 as China\u2019s Ministry of Public Security, its top police agency, set aside billions of dollars under two government plans, called Skynet and Sharp Eyes, to computerize surveillance, policing and intelligence collection.\nIn a statement, a SenseTime spokeswoman said she checked with \u201crelevant teams,\u201d who were not aware its technology was being used to profile. Megvii said in a statement it was focused on \u201ccommercial not political solutions,\u201d adding, \u201cwe are concerned about the well-being and safety of individual citizens, not about monitoring groups.\u201d CloudWalk and Yitu did not respond to requests for comment. \nChina\u2019s Ministry of Public Security did not respond to a faxed request for comment. \nSelling products with names like Fire Eye, Sky Eye and Dragonfly Eye, the start-ups promise to use A.I. to analyze footage from China\u2019s surveillance cameras. The technology is not mature \u2014 in 2017 Yitu promoted a one-in-three success rate when the police responded to its alarms at a train station \u2014 and many of China\u2019s cameras are not powerful enough for facial recognition software to work effectively. \nYet they help advance China\u2019s architecture for social control. To make the algorithms work, the police have put together face-image databases for people with criminal records, mental illnesses, records of drug use, and those who petitioned the government over grievances, according to two of the people and procurement documents. A national database of criminals at large includes about 300,000 faces, while a list of people with a history of drug use in the city of Wenzhou totals 8,000 faces, they said.\nUsing a process called machine learning, engineers feed data to artificial intelligence systems to train them to recognize patterns or traits. In the case of the profiling, they would provide thousands of labeled images of both Uighurs and non-Uighurs. That would help generate a function to distinguish the ethnic group. \nThe A.I. companies have taken money from major investors. Fidelity International and Qualcomm Ventures were a part of a consortium that invested $620 million in SenseTime. Sequoia invested in Yitu. Megvii is backed by Sinovation Ventures, the fund of the well-known Chinese tech investor Kai-Fu Lee. \nA Sinovation spokeswoman said the fund had recently sold a part of its stake in Megvii and relinquished its seat on the board. Fidelity declined to comment. Sequoia and Qualcomm did not respond to emailed requests for comment.\nMr. Lee, a booster of Chinese A.I., has argued that China has an advantage in developing A.I. because its leaders are less fussed by \u201clegal intricacies\u201d or \u201cmoral consensus.\u201d \n\u201cWe are not passive spectators in the story of A.I. \u2014 we are the authors of it,\u201d Mr. Lee wrote last year. \u201cThat means the values underpinning our visions of an A.I. future could well become self-fulfilling prophecies.\u201d He declined to comment on his fund\u2019s investment in Megvii or its practices.\nEthnic profiling within China\u2019s tech industry isn\u2019t a secret, the people said. It has become so common that one of the people likened it to the short-range wireless technology Bluetooth. Employees at Megvii were warned about the sensitivity of discussing ethnic targeting publicly, another person said.\nChina has devoted major resources toward tracking Uighurs, citing ethnic violence in Xinjiang and Uighur terrorist attacks elsewhere. Beijing has thrown hundreds of thousands of Uighurs and others in Xinjiang into re-education camps. \nThe software extends the state\u2019s ability to label Uighurs to the rest of the country. One national database stores the faces of all Uighurs who leave Xinjiang, according to two of the people.\nGovernment procurement documents from the past two years also show demand has spread. In the city of Yongzhou in southern Hunan Province, law enforcement officials sought software to \u201ccharacterize and search whether or not someone is a Uighur,\u201d according to one document.\nIn two counties in Guizhou Province, the police listed a need for Uighur classification. One asked for the ability to recognize Uighurs based on identification photos at better than 97 percent accuracy. In the central megacity of Chongqing and the region of Tibet, the police put out tenders for similar software. And a procurement document for Hebei Province described how the police should be notified when multiple Uighurs booked the same flight on the same day. \nA  study in 2018 by the authorities described a use for other types of databases. Co-written by a Shanghai police official, the paper said facial recognition systems installed near schools could screen for people included in databases of the mentally ill or crime suspects.\nOne database generated by Yitu software and reviewed by The Times showed how the police in the city of Sanmenxia used software running on cameras to attempt to identify residents more than 500,000 times over about a month beginning in mid-February.\nIncluded in the code alongside tags like \u201crec_gender\u201d and \u201crec_sunglasses\u201d was \u201crec_uygur,\u201d which returned a 1 if the software believed it had found a Uighur. Within the half million identifications the cameras attempted to record, the software guessed it saw Uighurs 2,834 times. Images stored alongside the entry would allow the police to double check.\nYitu and its rivals have ambitions to expand overseas. Such a push could easily put ethnic profiling software in the hands of other governments, said Jonathan Frankle, an A.I. researcher at the Massachusetts Institute of Technology.\n\u201cI don\u2019t think it\u2019s overblown to treat this as an existential threat to democracy,\u201d Mr. Frankle said. \u201cOnce a country adopts a model in this heavy authoritarian mode, it\u2019s using data to enforce thought and rules in a much more deep-seated fashion than might have been achievable 70 years ago in the Soviet Union. To that extent, this is an urgent crisis we are slowly sleepwalking our way into.\u201d", "date": "April 14, 2019", "href": "https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html", "tags": "face scans uighurs daily using \u201d one state a.i month part \u2018 software chinese police surveillance china profile recognition technology minoritylisten"}