{"title": "How A.I. Is Creating Building Blocks to Reshape Music and Art", "content": "MOUNTAIN VIEW, Calif. \u2014 In the mid-1990s, Douglas Eck worked as a database programmer in Albuquerque while moonlighting as a musician. After a day spent writing computer code inside a lab run by the Department of Energy, he would take the stage at a local juke joint, playing what he calls \u201cpunk-influenced bluegrass\u201d \u2014 \u201cJohnny Rotten crossed with Johnny Cash.\u201d But what he really wanted to do was combine his days and nights, and build machines that could make their own songs. \u201cMy only goal in life was to mix A.I. and music,\u201d Mr. Eck said.\nIt was a na\u00efve ambition. Enrolling as a graduate student at Indiana University, in Bloomington, not far from where he grew up, he pitched the idea to Douglas Hofstadter, the cognitive scientist who wrote the Pulitzer Prize-winning book on minds and machines, \u201cG\u00f6del, Escher, Bach: An Eternal Golden Braid.\u201d Mr. Hofstadter turned him down, adamant that even the latest artificial intelligence techniques were much too primitive. But over the next two decades, working on the fringe of academia, Mr. Eck kept chasing the idea, and eventually, the A.I. caught up with his ambition.\nLast spring, a few years after taking a research job at Google, Mr. Eck pitched the same idea he pitched Mr. Hofstadter all those years ago. The result is Project Magenta, a team of Google researchers who are teaching machines to create not only their own music but also to make so many other forms of art, including sketches, videos and jokes. With its empire of smartphones, apps and internet services, Google is in the business of communication, and Mr. Eck sees Magenta as a natural extension of this work.\n\u201cIt\u2019s about creating new ways for people to communicate,\u201d he said during a recent interview inside the small two-story building here that serves as headquarters for Google A.I. research.\nThe project is part of a growing effort to generate art through a set of A.I. techniques that have only recently come of age. Called deep neural networks, these complex mathematical systems allow machines to learn specific behavior by analyzing vast amounts of data. By looking for common patterns in millions of bicycle photos, for instance, a neural network can learn to recognize a bike. This is how Facebook identifies faces in online photos, how Android phones recognize commands spoken into phones, and how Microsoft Skype translates one language into another. But these complex systems can also create art. By analyzing a set of songs, for instance, they can learn to build similar sounds.\nAs Mr. Eck says, these systems are at least approaching the point \u2014 still many, many years away \u2014 when a machine can instantly build a new Beatles song or perhaps trillions of new Beatles songs, each sounding a lot like the music the Beatles themselves recorded, but also a little different. But that end game \u2014 as much a way of undermining art as creating it \u2014 is not what he is after. There are so many other paths to explore beyond mere mimicry. The ultimate idea is not to replace artists but to give them tools that allow them to create in entirely new ways.\nIn the 1990s, at that juke joint in New Mexico, Mr. Eck combined Johnny Rotten and Johnny Cash. Now, he is building software that does much the same thing. Using neural networks, he and his team are crossbreeding sounds from very different instruments \u2014 say, a bassoon and a clavichord \u2014 creating instruments capable of producing sounds no one has ever heard.\nMuch as a neural network can learn to identify a cat by analyzing hundreds of cat photos, it can learn the musical characteristics of a bassoon by analyzing hundreds of notes. It creates a mathematical representation, or vector, that identifies a bassoon. So, Mr. Eck and his team have fed notes from hundreds of instruments into a neural network, building a vector for each one. Now, simply by moving a button across a screen, they can combine these vectors to create new instruments. One may be 47 percent bassoon and 53 percent clavichord. Another might switch the percentages. And so on.\nFor centuries, orchestral conductors have layered sounds from various instruments atop one other. But this is different. Rather than layering sounds, Mr. Eck and his team are combining them to form something that didn\u2019t exist before, creating new ways that artists can work. \u201cWe\u2019re making the next film camera,\u201d Mr. Eck said. \u201cWe\u2019re making the next electric guitar.\u201d\nCalled NSynth, this particular project is only just getting off the ground. But across the worlds of both art and technology, many are already developing an appetite for building new art through neural networks and other A.I. techniques. \u201cThis work has exploded over the last few years,\u201d said Adam Ferris, a photographer and artist in Los Angeles. \u201cThis is a totally new aesthetic.\u201d\nIn 2015, a separate team of researchers inside Google created DeepDream, a tool that uses neural networks to generate haunting, hallucinogenic imagescapes from existing photography, and this has spawned new art inside Google and out. If the tool analyzes a photo of a dog and finds a bit of fur that looks vaguely like an eyeball, it will enhance that bit of fur and then repeat the process. The result is a dog covered in swirling eyeballs.\nAt the same time, a number of artists \u2014 like the well-known multimedia performance artist Trevor Paglen or the lesser-known Adam Ferris \u2014 are exploring neural networks in other ways. In January, Mr. Paglen gave a performance in an old maritime warehouse in San Francisco that explored the ethics of computer vision through neural networks that can track the way we look and move. While members of the avant-garde Kronos Quartet played onstage, for example, neural networks analyzed their expressions in real time, guessing at their emotions.\nThe tools are new, but the attitude is not. Allison Parrish, a New York University professor who builds software that generates poetry, points out that artists have been using computers to generate art since the 1950s. \u201cMuch like as Jackson Pollock figured out a new way to paint by just opening the paint can and splashing it on the canvas beneath him,\u201d she said, \u201cthese new computational techniques create a broader palette for artists.\u201d\nA year ago, David Ha was a trader with Goldman Sachs in Tokyo. During his lunch breaks he started toying with neural networks and posting the results to a blog under a pseudonym. Among other things, he built a neural network that learned to write its own Kanji, the logographic Chinese characters that are not so much written as drawn.\nSoon, Mr. Eck and other Googlers spotted the blog, and now Mr. Ha is a researcher with Google Magenta. Through a project called SketchRNN, he is building neural networks that can draw. By analyzing thousands of digital sketches made by ordinary people, these neural networks can learn to make images of things like pigs, trucks, boats or yoga poses. They don\u2019t copy what people have drawn. They learn to draw on their own, to mathematically identify what a pig drawing looks like.\nThen, you ask them to, say, draw a pig with a cat\u2019s head, or to visually subtract a foot from a horse or sketch a truck that looks like a dog or build a boat from a few random squiggly lines. Next to NSynth or DeepDream, these may seem less like tools that artists will use to build new works. But if you play with them, you realize that they are themselves art, living works built by Mr. Ha. A.I. isn\u2019t just creating new kinds of art; it\u2019s creating new kinds of artists.", "date": "Aug. 14, 2017", "href": "https://www.nytimes.com/2017/08/14/arts/design/google-how-ai-creates-new-music-and-new-artists-project-magenta.html", "tags": "like blocks creating reshape building eck music \u201d networks art neural new \u2014 a.i"}