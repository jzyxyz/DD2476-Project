{"title": "Face recognition police tools 'staggeringly inaccurate'", "content": "Police must address concerns over the use of facial recognition systems or may face legal action, the UK's privacy watchdog says.\nInformation Commissioner Elizabeth Denham said the issue had become a \"priority\" for her office.\nAn investigation by campaign group Big Brother Watch suggested the technology flagged up a \"staggering\" number of innocent people as suspects.\nBut police have defended the technology and say safeguards are in place.\nBig Brother Watch submitted freedom of information requests to every police force in the UK. \nTwo police forces acknowledged they were currently testing facial recognition cameras. \nThe Metropolitan Police used facial recognition at London's Notting Hill carnival in 2016 and 2017 and at a Remembrance Sunday event. \nIts system incorrectly flagged 102 people as potential suspects and led to no arrests.\nIn figures given to Big Brother Watch, South Wales Police said its technology had made 2,685 \"matches\" between May 2017 and March 2018 - but 2,451 were false alarms. \nLeicestershire Police tested facial recognition in 2015, but is no longer using it at events.\nPolice facial recognition cameras have been trialled at events such as football matches, festivals and parades.\nHigh-definition cameras detect all the faces in a crowd and compare them with existing police photographs, such as mugshots from previous arrests. \nAny potential matches are flagged for a police officer to investigate further. \nSouth Wales Police has defended its use of facial recognition software and says the system has improved with time.\n\"When we first deployed and we were learning how to use it... some of the digital images we used weren't of sufficient quality,\" said Deputy Chief Constable Richard Lewis. \"Because of the poor quality, it was identifying people wrongly. They weren't able to get the detail from the picture.\"\nIt said a \"number of safeguards\" prevented any action being taken against innocent people.\n\"Firstly, the operator in the van is able to see that the person identified in the picture is clearly not the same person, and it's literally disregarded at that point,\" said Mr Lewis.\n\"On a much smaller number of occasions, officers went and spoke to the individual... realised it wasn't them, and offered them the opportunity to come and see the van.\n\"At no time was anybody arrested wrongly, nobody's liberty was taken away from them.\"\nThe Metropolitan Police told the BBC it was testing facial recognition to see whether it could \"assist police in identifying known offenders in large events, in order to protect the wider public\".\n\"Regarding 'false' positive matches - we do not consider these as false positive matches because additional checks and balances are in place to confirm identification following system alerts,\" it said in a statement.\n\"All alerts against the watch list are deleted after 30 days. Faces in the video stream that do not generate an alert are deleted immediately.\"\nBut Big Brother Watch said it was concerned that facial recognition cameras would affect \"individuals' right to a private life and freedom of expression\".\nIt also raised concerns that photos of any \"false alarms\" were sometimes kept by police for weeks.\n\"Automated facial recognition technology is currently used by UK police forces without a clear legal basis, oversight or governmental strategy,\" the group said.\nBig Brother Watch wants police to stop using facial recognition technology. It has also called on the government to make sure that the police do not keep the photos of innocent people.\nInformation Commissioner Elizabeth Denham said police had to demonstrate that facial recognition was \"effective\" that no less intrusive methods were available.\n\"Should my concerns not be addressed I will consider what legal action is needed to ensure the right protections are in place for the public,\" said Ms Denham.\nThe Home Office told the BBC it plans to publish its biometrics strategy in June, and it \"continues to support police to respond to changing criminal activity and new demands\".\n\"When trialling facial recognition technologies, forces must show regard to relevant policies, including the Surveillance Camera Code of Practices and the Information Commissioner's guide,\" it said in a statement. ", "date": "15 May 2018", "href": "https://www.bbc.co.uk/news/technology-44089161", "tags": "face tools facial inaccurate recognition watch matches brother police technology big"}