{"title": "San Francisco Bans Facial Recognition Technology", "content": "SAN FRANCISCO \u2014 San Francisco, long at the heart of the technology revolution, took a stand against potential abuse on Tuesday by banning the use of facial recognition software by the police and other agencies.\nThe action, which came in an 8-to-1 vote by the Board of Supervisors, makes San Francisco the first major American city to block a tool that many police forces are turning to in the search for both small-time criminal suspects and perpetrators of mass carnage.\nThe authorities used the technology to help identify the suspect in the mass shooting at an Annapolis, Md., newspaper last June. But civil liberty groups have expressed unease about the technology\u2019s potential abuse by government amid fears that it may shove the United States in the direction of an overly oppressive surveillance state.\nAaron Peskin, the city supervisor who sponsored the bill, said that it sent a particularly strong message to the nation, coming from a city transformed by tech.\n\u201cI think part of San Francisco being the real and perceived headquarters for all things tech also comes with a responsibility for its local legislators,\u201d Mr. Peskin said. \u201cWe have an outsize responsibility to regulate the excesses of technology precisely because they are headquartered here.\u201d\nBut critics said that rather than focusing on bans, the city should find ways to craft regulations that acknowledge the usefulness of face recognition. \u201cIt is ridiculous to deny the value of this technology in securing airports and border installations,\u201d said Jonathan Turley, a constitutional law expert at George Washington University. \u201cIt is hard to deny that there is a public safety value to this technology.\u201d\nThere will be an obligatory second vote next week, but it is seen as a formality.\nSimilar bans are under consideration in Oakland and in Somerville, Mass., outside of Boston. In Massachusetts, a bill in the State Legislature would put a moratorium on facial recognition and other remote biometric surveillance systems. On Capitol Hill, a bill introduced last month would ban users of commercial face recognition technology from collecting and sharing data for identifying or tracking consumers without their consent, although it does not address the government\u2019s uses of the technology.\nMatt Cagle, a lawyer with the A.C.L.U. of Northern California, on Tuesday summed up the broad concerns of facial recognition: The technology, he said, \u201cprovides government with unprecedented power to track people going about their daily lives. That\u2019s incompatible with a healthy democracy.\u201d\nThe San Francisco proposal, he added, \u201cis really forward-looking and looks to prevent the unleashing of this dangerous technology against the public.\u201d\nIn one form or another, facial recognition is already being used in many American airports and big stadiums, and by a number of other police departments. The pop star Taylor Swift has reportedly incorporated the technology at one of her shows, using it to help identify stalkers.\nThe facial recognition fight in San Francisco is largely theoretical \u2014 the police department does not currently deploy such technology, and it is only in use at the international airport and ports that are under federal jurisdiction and are not impacted by the legislation.\nSome local homeless shelters use biometric finger scans and photos to track shelter usage, said Jennifer Friedenbach, the executive director of the Coalition on Homelessness. The practice has driven undocumented residents away from the shelters, she said.\nStill, it has been a particularly charged topic in a city with a rich history of incubating dissent and individual liberties, but one that has also suffered lately from high rates of property crime.\nThe ban prohibits city agencies from using facial recognition technology, or information gleaned from external systems that use the technology. It is part of a larger legislative package devised to govern the use of surveillance technologies in the city that requires local agencies to create policies controlling their use of these tools. There are some exemptions, including one that would give prosecutors a way out if the transparency requirements might interfere with their investigations.\nStill, the San Francisco Police Officers Association, an officers\u2019 union, said the ban would hinder their members\u2019 efforts to investigate crime.\n\u201cAlthough we understand that it\u2019s not a 100 percent accurate technology yet, it\u2019s still evolving,\u201d said Tony Montoya, the president of the association. \u201cI think it has been successful in at least providing leads to criminal investigators.\u201d\nMr. Cagle and other experts said that it was difficult to know exactly how widespread the technology was in the United States. \u201cBasically, governments and companies have been very secretive about where it\u2019s being used, so the public is largely in the dark about the state of play,\u201d he said.\nBut Dave Maass, the senior investigative researcher at the Electronic Frontier Foundation, offered a partial list of police departments that he said used the technology, including Las Vegas, Orlando, San Jose, San Diego, New York City, Boston, Detroit and Durham, N.C.\nOther users, Mr. Maass said, include the Colorado Department of Public Safety, the Pinellas County Sheriff\u2019s Office, the California Department of Justice and the Virginia State Police.\nU.S. Customs and Border Protection is now using facial recognition in many airports and ports of sea entry. At airports, international travelers stand before cameras, then have their pictures matched against photos provided in their passport applications. The agency says the process complies with privacy laws, but it has still come in for criticism from the Electronic Privacy Information Center, which argues that the government, though promising travelers that they may opt out, has made it increasingly difficult to do so.\nBut there is a broader concern. \u201cWhen you have the ability to track people in physical space, in effect everybody becomes subject to the surveillance of the government,\u201d said Marc Rotenberg, the group\u2019s executive director.\nIn the last few years, facial recognition technology has improved and spread at lightning speed, powered by the rise of cloud computing, machine learning and extremely precise digital cameras. That has meant once-unimaginable new features for users of smartphones, who may now use facial recognition to unlock their devices, and to tag and sort photos.\nBut some experts fear the advances are outstripping government\u2019s ability to set guardrails to protect privacy.\nMr. Cagle and others said that a worst-case scenario already exists in China, where facial recognition is used to keep close tabs on the Uighurs, a largely Muslim minority, and is being integrated into a national digital panopticon system powered by roughly 200 million surveillance cameras.\nAmerican civil liberties advocates warn that the ability of facial surveillance to identify people at a distance, or online, without their knowledge or consent presents unique risks \u2014 threatening Americans\u2019 ability to freely attend political protests or simply go about their business anonymously in public. Last year, Bradford L. Smith, the president of Microsoft, warned that the technology was too risky for companies to police on their own and asked Congress to oversee its use.\nThe battle over the technology intensified last year after two researchers published a study showing bias in some of the most popular facial surveillance systems. Called Gender Shades, the study reported that systems from IBM and Microsoft were much better at identifying the gender of white men\u2019s faces than they were at identifying the gender of darker-skinned or female faces.\nAnother study this year reported similar problems with Amazon\u2019s technology, called Rekognition. Microsoft and IBM have since said they improved their systems, while Amazon has said it updated its system since the researchers tested it and had found no differences in accuracy.\nWarning that African-Americans, women and others could easily be incorrectly identified as suspects and wrongly arrested, the American Civil Liberties Union and other nonprofit groups last year called on Amazon to stop selling its technology to law enforcement.\nBut even with improvements in accuracy, civil rights advocates and researchers warn that, in the absence of government oversight, the technology could easily be misused to surveil immigrants or unfairly target African-Americans or low-income neighborhoods. In a recent essay, Luke Stark, a postdoctoral researcher at Microsoft Research Montreal, described facial surveillance as \u201cthe plutonium of artificial intelligence,\u201d arguing that it should be \u201crecognized as anathema to the health of human society, and heavily restricted as a result.\u201d\nAlvaro Bedoya, who directs Georgetown University\u2019s Center on Privacy and Technology, said that more than 30 states allow local or state authorities, or the F.B.I., to search their driver\u2019s license photos.\nMr. Bedoya said that these images are tantamount to being in a perpetual police lineup, as law enforcement agencies use them to check against the faces of suspected criminals. He said that the difference is that an algorithm, not a human being, is pointing to the suspect.\nHe also said that comprehensive regulation of the technology is sorely lacking. \u201cThis is the most pervasive and risky technology of the 21st century,\u201d he said.\nDaniel Castro, director of the Center for Data Innovation at the Information Technology and Innovation Foundation, is among those who opposed the idea of a ban. He said he would prefer to see face-recognition data accessible to the police only if they have secured a warrant from a judge, following guidelines the Supreme Court has set for other forms of electronic surveillance.\nBut proponents of the bans say they are an effort to hit the pause button and study the matter before harm is done. The proposed ban in Somerville, the Boston suburb, was sponsored by a councilor, Ben Ewen-Campen. \u201cThe government and the public don\u2019t have a handle on what the technology is and what it will become,\u201d he said on Tuesday.\nNext door in Boston, Ed Davis, the former police commissioner, said it was \u201cpremature to be banning things.\u201d Mr. Davis, who led the department during the Boston Marathon attack, said that no one in the United States wanted to follow the Chinese model.\nBut he also sees the potential. \u201cThis technology is still developing,\u201d he said, \u201cand as it improves, this could be the answer to a lot of problems we have about securing our communities.\u201d\nJoel Engardio, the vice president of Stop Crime SF, said that he agreed that current facial recognition technologies were flawed, but said that the city should not prohibit their use in the future, if they were improved.\n\u201cInstead of an outright ban, why not a moratorium?\u201d Mr. Engardio asked. \u201cLet\u2019s keep the door open for when the technology improves. I\u2019m not a fan of banning things when eventually it could actually be helpful.\u201d", "date": "May 14, 2019", "href": "https://www.nytimes.com/2019/05/14/us/facial-recognition-ban-san-francisco.html#commentsContainer", "tags": "francisco facial \u201c city recognition san police bans use technology"}