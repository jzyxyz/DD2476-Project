{"title": "Competing With the Giants in Race to Build Self-Driving Cars", "content": "PALO ALTO, Calif. \u2014 Before the car can drive without a human, one must first get behind the wheel.\nAs the driver at this company accelerates, stops and turns on local streets, sensors on the car record what he sees and track how he responds. Then a team of engineers builds software that can learn how to behave from that data.\nThe software is installed in the car, and it can drive on its own. In the end, the car mimics choices made by the human driver.\nThis is how things work at Aurora Innovation, a start-up founded by three veterans of autonomous vehicle research, including Chris Urmson, who previously led the self-driving car project at Google.\nThe company\u2019s methods are part of a change sweeping across the world of self-driving cars: a kind of so-called machine learning technology that promises a chance for little companies like Aurora to compete with the giants of both the tech and automotive industries. With it, researchers can build and improve autonomous vehicles at a far more rapid pace \u2014 one of the reasons Aurora believes it can close the gap on companies that have been working on self-driving technology for years.\nOn Thursday, the year-old start-up said that it had agreed to supply self-driving technology to the Volkswagen Group and Hyundai, two of the world\u2019s largest car companies. Johann Jungwirth, the chief digital officer at the Volkswagen Group, which owns Audi, Porsche and six other major automotive brands including the flagship VW brand, said the company has been working with Aurora for several months, with an eye toward developing both autonomous cars and driverless taxi services.\nIn 2010, when Mr. Urmson and his colleagues at Google launched the autonomous vehicle movement, writing the computer code to guide their vehicles was a painstaking, line-by-line effort. But in recent years, a type of computer algorithm called a deep neural network has come in from the edges of academia to reinvent the way many technologies are built, including autonomous vehicles.\nThese algorithms can learn tasks on their own by analyzing vast amounts of data. \u201cIt used to be that a real smart Ph.D. sat in a cube for six months, and they would hand-code a detector\u201d that spotted objects on the road, Mr. Urmson said during a recent interview at Aurora\u2019s offices. \u201cNow, you gather the right kind of data and feed it to an algorithm, and a day later, you have something that works as well as that six months of work from the Ph.D.\u201d\nThe Google self-driving car project first used the technique to detect pedestrians. Since then, it has applied the same method to many other parts of the car, including systems that predict what will happen on the road and plan a route forward. Now, the industry as a whole is moving in the same direction.\nBut this shift raises questions. It is still unclear how regulators and lawyers \u2014 not to mention the general public \u2014 will view these methods. Because neural networks learn from such large amounts of data, relying on hours or even days of calculations, they operate in ways that their human designers cannot necessarily anticipate or understand. There is no means of determining exactly why a machine reaches a particular decision.\n\u201cThis is a big transition,\u201d said Noah Goodall, who explores regulatory and legal issues surrounding autonomous cars at the Virginia Transportation Research Council, an arm of the State Department of Transportation. \u201cIf you start using neural networks to control how a car moves and then it crashes, how do you explain why it crashed and why it won\u2019t happen again?\u201d\nThe seeds for this work were planted in 2012. Working with two other researchers at the University of Toronto, a graduate student named Alex Krizhevsky built a neural network that could recognize photos of everyday objects like flowers, dogs and cars. By analyzing thousands of flower photos, it could learn to recognize a flower in a matter of days. And it performed better than any system coded by hand.\nSoon, Mr. Krizhevsky and his collaborators moved to Google, and over the next few years, Google and its internet rivals broke new ground in artificial intelligence, using these concepts to identify objects in photos and to recognize commands spoken into smartphones, translate between languages and respond to internet search queries.\nOver the holiday break at the end of 2013, another Google researcher, Anelia Angelova, asked for Mr. Krizhevsky\u2019s help on the Google car project. Neither of them officially worked on the project. They were part of a separate A.I. lab called Google Brain. But they saw an opportunity.\nRather than trying to define for a computer what a pedestrian looked like, they created an algorithm that could allow a computer to learn what a pedestrian looked like. By analyzing thousands of street photos, their system could begin to identify the visual patterns that define a pedestrian, like the curve of a head or the bend of a leg. The method was so effective that Google began applying the technique to other parts of the project, including prediction and planning.\n\u201cIt was a big turning point,\u201d said Dmitri Dolgov, who was part of Google\u2019s original self-driving car team and is now chief technology officer at Waymo, the new company that oversees the project. \u201c2013 was pretty magical.\u201d\nMr. Urmson described this shift in much the same way. He believes the continued progress of these and other machine learning methods will be essential to building cars that can match and even exceed the behavior of human drivers.\nMirroring the work at Waymo, Aurora is building algorithms that can recognize objects on the road and anticipate and react to what other vehicles and pedestrians will do next. As Mr. Urmson explained, the software can learn what happens when a driver turns the vehicle in a particular direction at a particular speed on a particular type of road.\nLearning from human drivers in this way is an evolution of an old idea. In the early 1990s, researchers at Carnegie Mellon University built a car that learned relatively simple behavior. Last year, a team of researchers at Nvidia, the computer chip maker, published a paper showing how modern hardware can extend the idea to more complex behavior. But many researchers question whether carmakers can completely understand why neural networks make particular decisions and rule out unexpected behavior.\n\u201cFor cars or flying aircraft, there is a lot of concern over neural networks doing crazy things,\u201d said Mykel Kochenderfer, a robotics professor who oversees the Intelligent Systems Laboratory at Stanford University.\nSome researchers, for instance, have shown that neural networks trained to identify objects can be fooled into seeing things that aren\u2019t there \u2014 though many, including Mr. Kochenderfer, are working to develop ways of identifying and preventing unexpected behavior.\nLike Waymo, Toyota and others, Aurora says that its approach is more controlled than it might seem. The company layers cars with backup systems, so that if one system fails, another can offer a safety net. And rather than driving the car using a single neural network that learns all behavior from one vast pool of data \u2014 the method demonstrated by Nvidia \u2014 they break the task into smaller pieces.\nOne system detects traffic lights, for example. Another predicts what will happen next on the road in a particular kind of situation. A third chooses a response. And so on. The company can train and test and retrain each piece.\n\u201cHow do you get confidence that something works?\u201d asked Drew Bagnell, a machine learning specialist who helped found Aurora after leaving the self-driving car program at Uber. \u201cYou test it.\u201d\nMr. Goodall, the Virginia Department of Transportation researcher, said car designers must reassure both regulators and the public that these methods are reliable.\n\u201cThe onus is on them,\u201d he said.", "date": "Jan. 4, 2018", "href": "https://www.nytimes.com/2018/01/04/technology/self-driving-cars-aurora.html", "tags": "competing cars google mr. aurora \u201d build giants race neural car \u2014 self-driving"}