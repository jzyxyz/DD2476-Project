{"title": "Throw Your Laptop Into the Sea, the Surveillance Economy Will Still Win", "content": "This article is part of a limited-run newsletter. You can sign up here.\nYou can\u2019t solve a problem that you can\u2019t define. That\u2019s why I love this dual definition of privacy by Maciej Ceglowski, one of my favorite writers and thinkers on technology. It\u2019s from his written testimony submitted to the Senate Banking Committee last week.\nThe first definition is the classic one, that data privacy is \u201cthe idea of protecting designated sensitive material from unauthorized access.\u201d Easy enough. His second is much more profound and, as he puts it, \u201cuntil recently was so common and unremarkable that it would have made no sense to try to describe it.\u201d Here it is:\nWhat Ceglowski is really talking about is the ability to \u201copt out.\u201d It\u2019s a phrase that big tech companies love to use. Just toggle this button and you\u2019re free! David, the user, has control, not Goliath. This is, of course, quite disingenuous. As Ceglowski argues:\nWe\u2019ve built a society and economy that runs on surveillance, a world where the price for participation is tracking, targeting and disclosure of data. \u201cOpting out\u201d might as well mean heading to Walden Pond (and even then it\u2019s likely that, in preparation for your journey to Thoreau\u2019s cabin, you\u2019d be targeted by ads for self-reliance books on Amazon, freeze-dried prepper meals and 12 different iPhone meditation apps).\nI called up Ceglowski after his trip to Washington to inquire about the experience and what he thinks we can do to make opting out less of a pipe dream. Like anyone with a decent understanding of how the web works, he has a healthy skepticism that we\u2019ll rein in privacy violations, but his one potential area of optimism really stuck with me. It\u2019s the concept of positive regulation.\nThe gist is that Google and Facebook and the entrenched platforms are truly vulnerable only in one area: privacy. He argues for a legally binding framework with harsh penalties (criminal liability) for playing fast and loose with data. The logic is that big tech companies are so reliant on invasive privacy practices and deal with so much information that there\u2019s no way they can play by such rules. But new entrants \u2014 companies that are smaller and that actually put a premium on privacy \u2014 might be able to differentiate themselves and disrupt the space.\n\u201cIf we use privacy constructively and create a legal framework, we can incentivize those who want to go up against the entrenched players by marketing themselves as explicitly privacy-focused,\u201d he told me.\nPerhaps most important, Ceglowski\u2019s approach would finally test the idea of just how much internet users value data privacy. \u201cIt is possible that the tech giants are right, and people want services for free, no matter the privacy cost. It is also possible that people value privacy, and will pay extra for it, just like many people now pay a premium for organic fruit,\u201d he wrote in his statement.\nOver the phone, he explained that, while it might seem small, if real people on the internet vote with their wallets to use privacy-focused services over big data-sucking platforms like Facebook and Google, the effect could be profound. He cited the telemarketing wars of the early 2000s as an example. \n\u201cWhen telemarketers were fighting the \u2018do not call\u2019 list they argued that people loved having the opportunity to hear about great deals and products via phone during dinner time,\u201d he said. \u201cBut once the regulation passed, everyone signed up for that list and it became obvious that the industry\u2019s argument was laughable.\u201d\nSo far, nobody\u2019s been able to poke a hole in big tech companies\u2019 argument that we enjoy their services enough that we\u2019re O.K. with constant privacy violations. Perhaps that\u2019s only because, as Ceglowski suggests, it\u2019s all we know. \u201cIn the best case, you could have companies who can make the argument that real people care about privacy, as long as they\u2019re given a realistic option,\u201d he said. \nIn other words, it\u2019s actual opting out. \nToday\u2019s archive pick is a pair of articles documenting the story Ceglowski told above about the \u201cdo not call\u201d list. The first a 2003 report that centers on efforts by congressmen including Representative Ed Markey, Democrat of Massachusetts, to put the list into effect after court rulings against it:\nThe second is from November 2005 that reflects on the success of the list two years later. It\u2019s especially striking if you apply it to our current sentiments about privacy and the possibility of consumer-empowering legislation:\nYou get a lot of email. And since many of us are constantly coughing up our email address to do everything from online shopping to subscribing to news sites, inboxes can quickly shift from a helpful feed to a rat\u2019s nest of spam.\n Much of this isn\u2019t anything to worry about. But occasionally, your email address can fall into the hands of bad actors who\u2019ll use it to bombard you with garbage and, worse yet, mount phishing attacks that seek to get you to inadvertently share your passwords or personal information. These attacks are getting more sophisticated and can dupe even the most cautious internet dwellers.\nSo one way to protect your privacy is to create a disposable email address when you\u2019re signing up for services. It makes your inbox less chaotic and focused on real correspondence with real people you know. It\u2019s also a great way to inoculate yourself from attacks. \nThere\u2019s a number of burner email companies, some of which auto-delete after only 10 minutes (great if you need to sign into a weird or suspect site that requires an email). Some to check out: MaskMe, which lets you create unlimited burners; BurnerMail; Mailinator, which self-deletes; and 10 Minute Mail, which is self-explanatory.\n And Digital Trends has a nice primer here on how to create email tags on Gmail (not quite a burner, but a helpful filter that will delete unwanted mail).\nQ: I am in a profession that requires me sometimes to meet remotely with colleagues. Is there a relatively safe platform, or are they all invasive?\nA: Before digging in, I\u2019ll parrot some grim-but-important advice I received from Amir Orad, a security expert with deep experience in the information wars, that changed the way I think about privacy. \u201cWhatever you do online, operate with the assumption that every picture, email, communication will be one day made public on a big bulletin board,\u201d he said. \u201cIf you don\u2019t accept that you\u2019re not living in reality.\u201d \nTerrifying, I know. But I take that less literally and more as a guide for how to discuss things online. If you\u2019re dealing with intensely personal information or very, very private, high-level corporate information \u2014 if the stakes are obscenely high \u2014 then nothing is better than face-to-face conversation. An encrypted phone call on a service like Signal is also very good and (so far) reliable. \nBut face to face isn\u2019t always possible\u00a0and sometimes the information isn\u2019t top-secret\u00a0\u2014 you just want to know you have a reasonable expectation of security. To my knowledge, popular conferencing platforms like Zoom and GoToMeeting are Hipaa-compliant and offer end-to-end encryption. They also have security white papers, like this one, which gives the fine print. Privacy seems to be a competitive feature for these services, so my advice is to talk to the I.T. team at your workplace to determine which platform they use and then poke around a bit. \nLastly, you can push for your workplace to develop working guidelines for calls that can help police the weakest link in any security chain: the humans on the call. Some guidelines might look like this. A few examples might be: \u201cUsers must get permission to record a video conference from everyone on the call\u201d and \u201cVideo conferences conducted at a user\u2019s desk should train the camera to focus on the user\u2019s face, and any visible confidential data should be removed from camera view.\u201d\nHere\u2019s a horror story about GPS trackers that can remotely turn on your microphone.\nA good explainer on the recent WhatsApp hack and what to do.\nI was deeply fascinated by this piece on health aides \u201ccrossing the line\u201d on privacy.\nNBC News has a good look at the implications of the California privacy law that goes into effect next year and the ways it could change the internet.\nFollow @privacyproject on Twitter and The New York Times Opinion Section on Facebook and Instagram.", "date": "May 14, 2019", "href": "https://www.nytimes.com/2019/05/14/opinion/data-privacy.html", "tags": "win ceglowski throw laptop \u201d email economy one companies sea information like privacy surveillance still"}